{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading all the data from Google Query to my notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Set the project ID here\n",
    "project_id = \"velvety-ring-349218\"\n",
    "\n",
    "# Create a BigQuery client\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Set the name of the source table\n",
    "table_id = \"velvety-ring-349218.Stack_Overflow.posts_answers\"\n",
    "\n",
    "# Set the path to the JSON file to save\n",
    "destination_file_name = \"/Users/izabellamartirosyan/Desktop/Capstone/post_answers.json\"\n",
    "\n",
    "# Define the SQL query to select the desired columns\n",
    "query = \"\"\"\n",
    "SELECT id, parent_id, owner_user_id, body, comment_count, creation_date, last_activity_date, score\n",
    "FROM `velvety-ring-349218.Stack_Overflow.posts_answers`\n",
    "WHERE creation_date BETWEEN '2022-04-01' AND '2022-04-30';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# Save the query results to a JSON file\n",
    "with open(destination_file_name, \"w\") as destination_file:\n",
    "    query_job.result().to_dataframe().to_json(destination_file, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Set the project ID here\n",
    "project_id = \"velvety-ring-349218\"\n",
    "\n",
    "# Create a BigQuery client\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Set the name of the source table\n",
    "table_id = \"velvety-ring-349218.Stack_Overflow.badges\"\n",
    "\n",
    "# Set the path to the CSV file to save\n",
    "destination_file_name = \"/Users/izabellamartirosyan/Desktop/Capstone/badges.csv\"\n",
    "\n",
    "# Define the SQL query to select the desired columns\n",
    "query = \"\"\"\n",
    "SELECT id, user_id, name, date, class, tag_based\n",
    "    FROM `velvety-ring-349218.Stack_Overflow.badges` WHERE date BETWEEN '2022-04-01' AND '2022-04-30';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# Save the query results to a JSON file\n",
    "with open(destination_file_name, \"w\") as destination_file:\n",
    "    query_job.result().to_dataframe().to_json(destination_file, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import db_dtypes\n",
    "\n",
    "# Set the project ID here\n",
    "project_id = \"velvety-ring-349218\"\n",
    "\n",
    "# Create a BigQuery client\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Set the name of the source table\n",
    "table_id = \"velvety-ring-349218.Stack_Overflow.comments\"\n",
    "\n",
    "# Set the path to the CSV file to save\n",
    "destination_file_name = \"/Users/izabellamartirosyan/Desktop/Capstone/comments.csv\"\n",
    "\n",
    "# Define the SQL query to select the desired columns\n",
    "query = \"\"\"\n",
    "SELECT id, user_id, post_id, text, score, creation_date, user_display_name \n",
    "    FROM `velvety-ring-349218.Stack_Overflow.comments` WHERE creation_date BETWEEN '2022-04-01' AND '2022-04-30';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# Save the query results to a JSON file\n",
    "with open(destination_file_name, \"w\") as destination_file:\n",
    "    query_job.result().to_dataframe().to_json(destination_file, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import db_dtypes\n",
    "\n",
    "# Set the project ID here\n",
    "project_id = \"velvety-ring-349218\"\n",
    "\n",
    "# Create a BigQuery client\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Set the name of the source table\n",
    "table_id = \"velvety-ring-349218.Stack_Overflow.post_history\"\n",
    "\n",
    "# Set the path to the CSV file to save\n",
    "destination_file_name = \"/Users/izabellamartirosyan/Desktop/Capstone/post_history.csv\"\n",
    "\n",
    "# Define the SQL query to select the desired columns\n",
    "query = \"\"\"\n",
    "SELECT id, user_id, revision_guid, creation_date, text, comment \n",
    "    FROM `velvety-ring-349218.Stack_Overflow.post_history` WHERE creation_date BETWEEN '2022-04-01' AND '2022-04-30';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# Save the query results to a JSON file\n",
    "with open(destination_file_name, \"w\") as destination_file:\n",
    "    query_job.result().to_dataframe().to_json(destination_file, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import db_dtypes\n",
    "\n",
    "# Set the project ID here\n",
    "project_id = \"velvety-ring-349218\"\n",
    "\n",
    "# Create a BigQuery client\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Set the name of the source table\n",
    "table_id = \"velvety-ring-349218.Stack_Overflow.post_links\"\n",
    "\n",
    "# Set the path to the CSV file to save\n",
    "destination_file_name = \"/Users/izabellamartirosyan/Desktop/Capstone/post_links.csv\"\n",
    "\n",
    "# Define the SQL query to select the desired columns\n",
    "query = \"\"\"\n",
    "SELECT id, related_post_id, link_type_id, creation_date\n",
    "    FROM `velvety-ring-349218.Stack_Overflow.post_links` WHERE creation_date BETWEEN '2022-04-01' AND '2022-04-30';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# Save the query results to a JSON file\n",
    "with open(destination_file_name, \"w\") as destination_file:\n",
    "    query_job.result().to_dataframe().to_json(destination_file, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import db_dtypes\n",
    "\n",
    "# Set the project ID here\n",
    "project_id = \"velvety-ring-349218\"\n",
    "\n",
    "# Create a BigQuery client\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Set the name of the source table\n",
    "table_id = \"velvety-ring-349218.Stack_Overflow.posts_questions\"\n",
    "\n",
    "# Set the path to the CSV file to save\n",
    "destination_file_name = \"/Users/izabellamartirosyan/Desktop/Capstone/posts_questions.csv\"\n",
    "\n",
    "# Define the SQL query to select the desired columns\n",
    "query = \"\"\"\n",
    "SELECT id, post_type_id, owner_user_id, title, body, tags, view_count, answer_count, comment_count, favorite_count, creation_date, last_activity_date\n",
    "    FROM `velvety-ring-349218.Stack_Overflow.posts_questions` WHERE creation_date BETWEEN '2022-04-01' AND '2022-04-30';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# Save the query results to a JSON file\n",
    "with open(destination_file_name, \"w\") as destination_file:\n",
    "    query_job.result().to_dataframe().to_json(destination_file, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import db_dtypes\n",
    "\n",
    "# Set the project ID here\n",
    "project_id = \"velvety-ring-349218\"\n",
    "\n",
    "# Create a BigQuery client\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Set the name of the source table\n",
    "table_id = \"velvety-ring-349218.Stack_Overflow.tags\"\n",
    "\n",
    "# Set the path to the CSV file to save\n",
    "destination_file_name = \"/Users/izabellamartirosyan/Desktop/Capstone/tags.csv\"\n",
    "\n",
    "# Define the SQL query to select the desired columns\n",
    "query = \"\"\"\n",
    "SELECT id, tag_name\n",
    "    FROM `velvety-ring-349218.Stack_Overflow.tags`\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# Save the query results to a JSON file\n",
    "with open(destination_file_name, \"w\") as destination_file:\n",
    "    query_job.result().to_dataframe().to_json(destination_file, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import db_dtypes\n",
    "\n",
    "# Set the project ID here\n",
    "project_id = \"velvety-ring-349218\"\n",
    "\n",
    "# Create a BigQuery client\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Set the name of the source table\n",
    "table_id = \"velvety-ring-349218.Stack_Overflow.users\"\n",
    "\n",
    "# Set the path to the CSV file to save\n",
    "destination_file_name = \"/Users/izabellamartirosyan/Desktop/Capstone/users.csv\"\n",
    "\n",
    "# Define the SQL query to select the desired columns\n",
    "query = \"\"\"\n",
    "SELECT id, display_name, location, reputation, views, up_votes, down_votes, creation_date, last_access_date\n",
    "    FROM `velvety-ring-349218.Stack_Overflow.users` WHERE creation_date BETWEEN '2022-04-01' AND '2022-04-30';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# Save the query results to a JSON file\n",
    "with open(destination_file_name, \"w\") as destination_file:\n",
    "    query_job.result().to_dataframe().to_json(destination_file, orient=\"records\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
